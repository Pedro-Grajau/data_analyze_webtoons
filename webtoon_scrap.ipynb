{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webtoon_scrap.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOzsJVPmHDRSAgbHjMIEdPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pedro-Grajau/data_analyze_webtoons/blob/main/webtoon_scrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qESL4HG4Iadh"
      },
      "source": [
        "* Instalando o kora, uma biblioteca que facilita o uso de ferramentas como o Selenium dentro do Google Colab\n",
        "* Link para a biblioteca: https://pypi.org/project/kora/ \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALq05CiSAHgP"
      },
      "source": [
        "!pip install kora -q"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tTEo9rUI3eh"
      },
      "source": [
        "* **Importando uma base de dados de autores adquirida nesse link: https://www.webtoons.com/en/notice/detail?noticeNo=1609**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF2S0EKA4fUC"
      },
      "source": [
        "autores_txt = open(\"autores_webtoons.txt\", \"r\")\n",
        "autores_webtoons = [x.strip() for x in autores_txt.readlines()]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2a0jyJtJX_4"
      },
      "source": [
        "* **Fuções de tratamento para algumas entradas difíceis de lidar no seu estado \"normal\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWYzacu_nA7r"
      },
      "source": [
        "#Tratando algumas peculiaridades das entradas:\n",
        "\n",
        "def new_number(number):\n",
        "  if number == 'Like':\n",
        "    return 0\n",
        "  if 'M' in number:\n",
        "    if len(number) > 1:\n",
        "      return int(float(number.replace('M', '')) * 1000000)\n",
        "    return 1000000.0\n",
        "  else:\n",
        "    t, h = number.split(',')\n",
        "    number = int(t) * 1000 + int(h)\n",
        "    return number\n",
        "\n",
        "def get_html(search_data):\n",
        "  if search_data.status_code == 200:\n",
        "    return bs(search_data.content,'lxml')\n",
        "  else:\n",
        "    return f'{search_data.status_code}, : error'\n",
        "\n",
        "def remove_symbols(comic):\n",
        "  if \"?\" in comic:\n",
        "    comic = comic.replace(\"?\",\"a\")\n",
        "  if \"/\" in comic:\n",
        "    comic = comic.replace(\"/\",\"a\")\n",
        "  if \"#\" in comic:\n",
        "    comic = comic.replace(\"#\",\"a\")\n",
        "  return comic"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzoJyPKoJyMS"
      },
      "source": [
        "* **Função que foi criada para retornar todas as webtoons encontradas de acordo com o nome do autor.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUxur9iObngy"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "def author_comics(author):\n",
        "  titles = list()\n",
        "  search_url = \"https://www.webtoons.com/en/search?keyword=\" + author\n",
        "  search_data = requests.get(search_url)\n",
        "\n",
        "  #Check for 200 status code\n",
        "  soup = get_html(search_data)\n",
        "  \n",
        "  #Doing the scraping thing \n",
        "  search_result = soup.find(\"div\",class_=\"challenge_lst\")\n",
        "  all_results = search_result.find_all(class_=\"subj\")\n",
        "  a_links = search_result.find_all(class_=\"grade_num\")\n",
        "  title_data = search_result.find_all(\"a\", class_=\"challenge_item\")\n",
        "\n",
        "  #Inserting into a list of results\n",
        "  comics = [item.get_text().strip() for item in all_results]\n",
        "  views = [new_number(item.get_text()) for item in a_links]\n",
        "\n",
        "  for item in title_data:\n",
        "    title = item.get(\"href\")\n",
        "    title_number = int(title.split(\"=\")[1])\n",
        "    titles.append(title_number)\n",
        "  \n",
        "  return titles, views, comics"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB6Cf4rsJp0B"
      },
      "source": [
        "* **Aqui está a função responsável por pegar todos os dados desejados baseado pelo nome do autor da webtons. Os dados são: Nome, Título da Obra, Inscritos, Visualizações, Nota e Data de Lançamento**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Mc0q8A31A2Q"
      },
      "source": [
        "# Pesquisar todas as obras por autor (FEITO)\n",
        "# Pegar a obra com mais views (FEITO)\n",
        "\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException\n",
        "from kora.selenium import wd\n",
        "\n",
        "authors = list()\n",
        "\n",
        "for author in autores_webtoons:\n",
        "  titles, views, comics = author_comics(author)\n",
        "\n",
        "  #Catching the webtoon and your id by URL\n",
        "  max_index = views.index(max(views))\n",
        "  comic = comics[max_index]\n",
        "  title_number = titles[max_index]\n",
        "\n",
        "  if \"?\" in comic or \"/\" in comic or \"#\" in comic:\n",
        "    comic = remove_symbols(comic) \n",
        "\n",
        "  comic_url = f\"https://www.webtoons.com/en/challenge/{comic}/list?title_no={str(title_number)}\"\n",
        "  search_data = requests.get(comic_url)\n",
        "\n",
        "  #Check for 200 status code\n",
        "  soup = get_html(search_data)\n",
        "\n",
        "  #Title Name\n",
        "  title_name = soup.find(\"h3\" ,class_=\"subj _challengeTitle\")\n",
        "  title_name = \" \".join(title_name.get_text().split()[0:-1])\n",
        "\n",
        "  #Subs, views and rates\n",
        "  attributes = soup.find_all(\"em\" ,class_=\"cnt\")\n",
        "  subs, views, rate = [i.get_text() for i in attributes]\n",
        "\n",
        "  #genres\n",
        "  genres = soup.find_all(\"p\" ,class_=\"genre\")\n",
        "  genres = \"|\".join([i.get_text() for i in genres])\n",
        "\n",
        "  #Author\n",
        "  author = soup.find(\"span\" ,class_=\"author\").get_text()[:-11]\n",
        "\n",
        "  #Patrons\n",
        "  #patrons_number = soup.find(\"em\" ,id=\"patronCount\").get_text()\n",
        "  \n",
        "  #Finding Date of first chapter\n",
        "  first_episode_button = soup.find(\"a\" ,id = \"_btnEpisode\")\n",
        "  first_episode_link = first_episode_button.get(\"href\")\n",
        "  wd.get(first_episode_link)\n",
        "\n",
        "  #There is some webtoons with adult content, so they pop up a alert and we have\n",
        "  #to accept this alert to continue with our scraping\n",
        "  try:\n",
        "    WebDriverWait(wd, 3).until(EC.alert_is_present(),\n",
        "                                   'Timed out waiting for PA creation ' +\n",
        "                                   'confirmation popup to appear.')\n",
        "\n",
        "    alert = wd.switch_to.alert\n",
        "    alert.accept()\n",
        "    try:\n",
        "      date = wd.find_element_by_class_name(\"u_cbox_date\")\n",
        "      date = date.text\n",
        "      authors.append([author, title_name, subs, views, rate, genres, date])\n",
        "    except:\n",
        "      date = \"no_date\"\n",
        "      authors.append([author, title_name, subs, views, rate, genres, date])\n",
        "\n",
        "  except:\n",
        "    try:\n",
        "      date = wd.find_element_by_class_name(\"u_cbox_date\")\n",
        "      date = date.text\n",
        "      authors.append([author, title_name, subs, views, rate, genres, date])\n",
        "    except:\n",
        "      date = \"no_date\"\n",
        "      authors.append([author, title_name, subs, views, rate, genres, date])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1LOYKoPLVEc"
      },
      "source": [
        "* **Colocando os dados obtidos por meio de scraping e colocando eles dentro de um arquivo csv para uma futura análise visual de dados**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL3OrWuRcEgH"
      },
      "source": [
        "import csv\n",
        "\n",
        "header = [\"Author\", \"Webtoon\", \"Subscribed\", \"View\", \"Rate\", \"Genre\", \"Date\"]\n",
        "with open('webtoons.csv', 'w', encoding='UTF8', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(authors)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAJ8bTxwLlBn"
      },
      "source": [
        "* **Finalemente, a visualização do DataFrame usando a biblioteca pandas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "9JYzskQ380dm",
        "outputId": "f01af64e-9d52-4143-e5f8-4826bbd1e5a8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('webtoons.csv')\n",
        "\n",
        "data.head(20)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Author</th>\n",
              "      <th>Webtoon</th>\n",
              "      <th>Subscribed</th>\n",
              "      <th>View</th>\n",
              "      <th>Rate</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beimuyo</td>\n",
              "      <td>YOU ARE MY BFF (LGBTQ+)</td>\n",
              "      <td>252.5K</td>\n",
              "      <td>56.1M</td>\n",
              "      <td>9.53</td>\n",
              "      <td>Drama|Romance</td>\n",
              "      <td>Nov 6, 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cathy octo /erry</td>\n",
              "      <td>Maid for Hire</td>\n",
              "      <td>205.3K</td>\n",
              "      <td>13.9M</td>\n",
              "      <td>9.72</td>\n",
              "      <td>Romance|Comedy</td>\n",
              "      <td>Sep 3, 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cheruke</td>\n",
              "      <td>Domestic Beast</td>\n",
              "      <td>100.7K</td>\n",
              "      <td>8.4M</td>\n",
              "      <td>9.80</td>\n",
              "      <td>Fantasy|Slice of life</td>\n",
              "      <td>Nov 10, 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EmAuthor</td>\n",
              "      <td>Papa Ai</td>\n",
              "      <td>86.4K</td>\n",
              "      <td>6.7M</td>\n",
              "      <td>9.75</td>\n",
              "      <td>Comedy|Slice of life</td>\n",
              "      <td>Sep 13, 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fawnduu</td>\n",
              "      <td>My Dragon Girlfriend</td>\n",
              "      <td>262.8K</td>\n",
              "      <td>90.6M</td>\n",
              "      <td>9.49</td>\n",
              "      <td>Romance|Slice of life</td>\n",
              "      <td>Mar 21, 2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Fuzzzzyy</td>\n",
              "      <td>Out of Sight, Out of Body</td>\n",
              "      <td>188.7K</td>\n",
              "      <td>19.4M</td>\n",
              "      <td>9.80</td>\n",
              "      <td>Romance|Supernatural</td>\n",
              "      <td>Apr 17, 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Kirinu</td>\n",
              "      <td>Love n Life</td>\n",
              "      <td>672.9K</td>\n",
              "      <td>70.1M</td>\n",
              "      <td>9.28</td>\n",
              "      <td>Romance|Fantasy</td>\n",
              "      <td>Jun 28, 2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>loonytwin</td>\n",
              "      <td>EYES ON ME</td>\n",
              "      <td>920.3K</td>\n",
              "      <td>225.9M</td>\n",
              "      <td>9.47</td>\n",
              "      <td>Romance|Drama</td>\n",
              "      <td>Dec 9, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Merryweatherey</td>\n",
              "      <td>Clinic of Horrors</td>\n",
              "      <td>725K</td>\n",
              "      <td>54.7M</td>\n",
              "      <td>9.72</td>\n",
              "      <td>Comedy|Horror</td>\n",
              "      <td>Mar 7, 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>misterrico</td>\n",
              "      <td>Scripted Love</td>\n",
              "      <td>157.8K</td>\n",
              "      <td>42.3M</td>\n",
              "      <td>9.68</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "      <td>Jan 8, 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Mr. Circus Papa</td>\n",
              "      <td>Ghost Eyes</td>\n",
              "      <td>292.7K</td>\n",
              "      <td>123M</td>\n",
              "      <td>9.63</td>\n",
              "      <td>Horror|Supernatural</td>\n",
              "      <td>Feb 3, 2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Pet Foolery</td>\n",
              "      <td>Pixie and Brutus</td>\n",
              "      <td>682.8K</td>\n",
              "      <td>59.1M</td>\n",
              "      <td>9.87</td>\n",
              "      <td>Comedy|Heartwarming</td>\n",
              "      <td>Jun 9, 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>privateseru</td>\n",
              "      <td>Private Affairs</td>\n",
              "      <td>168.7K</td>\n",
              "      <td>25.1M</td>\n",
              "      <td>9.78</td>\n",
              "      <td>Romance|Drama</td>\n",
              "      <td>Apr 2, 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Sakurada Yana</td>\n",
              "      <td>My Weird Roommate</td>\n",
              "      <td>469.4K</td>\n",
              "      <td>127.8M</td>\n",
              "      <td>9.57</td>\n",
              "      <td>Slice of life|Romance</td>\n",
              "      <td>Jun 16, 2018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SomeBunny</td>\n",
              "      <td>That Awkward Magic!!</td>\n",
              "      <td>669.3K</td>\n",
              "      <td>123.3M</td>\n",
              "      <td>9.76</td>\n",
              "      <td>Romance|Fantasy</td>\n",
              "      <td>Jun 23, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>theyaoiarmy</td>\n",
              "      <td>All You Can Eat</td>\n",
              "      <td>185.3K</td>\n",
              "      <td>32.4M</td>\n",
              "      <td>9.74</td>\n",
              "      <td>Drama|Romance</td>\n",
              "      <td>Apr 2, 2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Aho Hansei</td>\n",
              "      <td>(BL)ACK</td>\n",
              "      <td>258.7K</td>\n",
              "      <td>29.8M</td>\n",
              "      <td>9.34</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "      <td>Mar 1, 2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Aina Palm</td>\n",
              "      <td>Idiots Don't Catch Colds</td>\n",
              "      <td>286.6K</td>\n",
              "      <td>41.4M</td>\n",
              "      <td>9.74</td>\n",
              "      <td>Romance|Comedy</td>\n",
              "      <td>Apr 17, 2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Alice Oseman</td>\n",
              "      <td>Heartstopper</td>\n",
              "      <td>227.1K</td>\n",
              "      <td>35.9M</td>\n",
              "      <td>9.92</td>\n",
              "      <td>Romance|School</td>\n",
              "      <td>Aug 25, 2019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>JMNP art</td>\n",
              "      <td>Seismic</td>\n",
              "      <td>32</td>\n",
              "      <td>256</td>\n",
              "      <td>10.00</td>\n",
              "      <td>Slice of life|Supernatural</td>\n",
              "      <td>Apr 3, 2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Author  ...          Date\n",
              "0            Beimuyo  ...   Nov 6, 2019\n",
              "1   cathy octo /erry  ...   Sep 3, 2020\n",
              "2            cheruke  ...  Nov 10, 2020\n",
              "3           EmAuthor  ...  Sep 13, 2019\n",
              "4            Fawnduu  ...  Mar 21, 2018\n",
              "5           Fuzzzzyy  ...  Apr 17, 2020\n",
              "6             Kirinu  ...  Jun 28, 2018\n",
              "7          loonytwin  ...   Dec 9, 2017\n",
              "8     Merryweatherey  ...   Mar 7, 2019\n",
              "9         misterrico  ...   Jan 8, 2020\n",
              "10   Mr. Circus Papa  ...   Feb 3, 2018\n",
              "11       Pet Foolery  ...   Jun 9, 2020\n",
              "12       privateseru  ...   Apr 2, 2020\n",
              "13     Sakurada Yana  ...  Jun 16, 2018\n",
              "14         SomeBunny  ...  Jun 23, 2017\n",
              "15       theyaoiarmy  ...   Apr 2, 2020\n",
              "16        Aho Hansei  ...   Mar 1, 2021\n",
              "17         Aina Palm  ...  Apr 17, 2017\n",
              "18      Alice Oseman  ...  Aug 25, 2019\n",
              "19          JMNP art  ...   Apr 3, 2021\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}